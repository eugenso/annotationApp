* database setup

Run
python manage.py makemigrations
to create migrations for those changes

Run
python manage.py migrate
to apply those changes to the database



Create a new admin
python manage.py createsuperuser



Run development server
python manage.py runserver

* Some stuff might be useful at some point

Connect to mysql-client
mysql -h 127.0.0.1 -P 3306 -u root


Serving static files in production
sudo python manage.py collectstatic


Install crispy form
pip install --upgrade django-crispy-forms



Requirements for MySQL for ubuntu
sudo apt-get install mysql-server-5.6
sudo apt-get install libmysqlclient-dev
sudo pip install mysqlclient



In annotationApp/annotationApp/settings.py change path in
DATABASES = {
    'default': {
        # 'ENGINE': 'django.db.backends.sqlite3',
        # 'NAME': os.path.join(BASE_DIR, 'db.sqlite3'),
        'ENGINE': 'django.db.backends.mysql',
        'OPTIOpNS': {
            'read_default_file': '/home/kai/Dropbox/MA/code/annotationApp/my.cnf',
        },
    }
}



Create a database to be used by django
CREATE DATABASE annotationApp CHARACTER SET utf8;



{# Load CSS and JavaScript #}
{% bootstrap_css %}
{% bootstrap_javascript %}

export format

{doc_id: {"document": "Lorem ipsum ...",
          "annotations": [{"user": "eugen",
                           "labels": ["rot", "grün", "blau"],
                           "duration": "123"},
                          {...}]},
 doc_id: {...}}


add export
add label import via file
pause button
large database managable


jeder user soll jedes doc genau einmal annotieren
jedes Dokument soll x mal annotiert werden egal von welchem user
naive bayes online implementieren
manuelle eingabe von beispielen.
        Text eingeben -> klassifizieren
        Label korregieren -> trainieren
        konfidenz scores ausgeben (label w/)
lernkurve


für bessere lesbarkeit die prior p(t|c) total in probability e^
deploy
techinscher report
mit den daten mach ein batch learner und evaluiere deinen classifier bbau eine learnkurve.
perceptron online classifier
wenn neues label hinzugefügt wird bei TRaining->classify nicht das neue label angezeigt.

* 30.09.2016

+implement priority queue for document selection. prioritise documents
that have at least one, but not the maximum amount of
annotations. maximum amount should be configurable. no double
annotation from one annotator.+


+Timestamp for the annotations proposal/no proposal field+

+wrong proposal?+

+config for how often do the annotator get no proposal+

+annotator bias regarding the proposed labels.+

* 14.10.2016

to addDocuments you have to have nltk stuff

+If no annotationQueue exist display something usefull not crap+

+check why there are double annoations+

highlight keywords in text box

+on page load set focus to text area+

+restrict js to site with focus on an element+

+If all documents are annotated catch the value error+

+remove http login+

+remove django src hack+

* 19.10.2016

+remove hard coded links with settings.SUB_SITE placeholder.+

+The createAnnotationQueue does not work+

* 21.10.2016

+max 150 words+

+keine proposals in der db+

+training mode does not work+

+doc live classification for proposals+

+was passiert wenn die parameter max 0 0 0+

* mögliche evaluationen:

stündliches erstelles der createAnnotaitonQueue und gesamtes test set
evaluieren. wie hoch ist der anteil der documente für die sich die
prediction ändert von std 0- std 1

wenn sich die prediction nicht mehr stark ändert kann man die live
prediction der proposals rausnehmen um den process zu
beschleunigen. Dann vergleichen zwischen proposal/non-proposal

* 25.10.2016

createLearningCurve not reasonable

timestamp for document when they are being added

** Question?
When is a document annotated? If its added at the
beginning(time) and put at the end of the queue. Will it always stay
at the end? if it is never annotated is the predicted label correct or
incorrect?

utf-8 error

Solve enter pop up loop

* 26.10.2016

RAM disc erstellen. und innoDB in den RAM myIsam tabellen kann man
frei kopieren. in mysql den pfand anpassen und in die RAM disc
schieben. Dann kann man die Annotationen loggen. Das Ausgabeformat in
dem JSON Format des exports.

Anstatt des foreign keys in nbc_word_given_label_count


find out how long it takes to create the queues

projekt in github einchecken und das projekt auf dem dev server laufen
lassen und auf dem production server die sentiment daten bereit
stellen.

enable cache on dev server für mysql

evaluate file command
